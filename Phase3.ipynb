{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583c8b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import Accuracy, F1Score, Precision, Recall\n",
    "from keras.optimizers import SGD, Adam, Adagrad, RMSprop, Nadam, AdamW\n",
    "from keras.src.losses import loss\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "#from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc70cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = r\"D:\\downloadsD\\archive\\dataset\\train\"\n",
    "VAL_DATA_DIR = r\"D:\\downloadsD\\archive\\dataset\\val\"\n",
    "\n",
    "MODEL_SAVE_DIR = r\"C:\\Users\\anar1\\Desktop\\CNN INGOLSTADT\\PHASE3MODEL\"\n",
    "\n",
    "MODEL_NAME = 'PHASE3_MODEL_PRETRAINED'\n",
    "TESTING_MODE = False #####\n",
    "\n",
    "\n",
    "MOMENTUM= 0.9\n",
    "NESTEROV=True\n",
    "\n",
    "IMG_SIZE = (224, 168)\n",
    "NUM_CLASSES = 9\n",
    "CHANNELS = 3\n",
    "\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-5\n",
    "PATIENCE = 15\n",
    "BATCH = 32\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86fbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'D:\\downloadsD\\archive\\dataset\\train':\n",
      "basement\n",
      "church\n",
      "entrance\n",
      "georgianum\n",
      "kreuztor\n",
      "ku\n",
      "pink\n",
      "room\n",
      "wfi\n"
     ]
    }
   ],
   "source": [
    "# target class names\n",
    "if os.path.isdir(TRAIN_DATA_DIR):\n",
    "    folder_contents = os.listdir(TRAIN_DATA_DIR)\n",
    "    print(f\"Contents of '{TRAIN_DATA_DIR}':\")\n",
    "    for item in folder_contents:\n",
    "        print(item)\n",
    "else:\n",
    "    print(f\"Error: '{TRAIN_DATA_DIR}' is not a valid directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41bbd9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data (Color Mode: rgb):\n",
      "Found 6769 files belonging to 9 classes.\n",
      "\n",
      "Loading Validation Data:\n",
      "Found 1698 files belonging to 9 classes.\n",
      "\n",
      "\n",
      "Classes of train: ['basement', 'church', 'entrance', 'georgianum', 'kreuztor', 'ku', 'pink', 'room', 'wfi']\n",
      "Classes of validation: ['basement', 'church', 'entrance', 'georgianum', 'kreuztor', 'ku', 'pink', 'room', 'wfi']\n"
     ]
    }
   ],
   "source": [
    "# selection of target folders\n",
    "selected_classes = [x for x in os.listdir(TRAIN_DATA_DIR)]\n",
    "\n",
    "# 1) Train split\n",
    "print(f\"Loading Training Data (Color Mode: rgb):\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    image_size=IMG_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "#2) Validation split\n",
    "print(\"\\nLoading Validation Data:\")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DATA_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH,\n",
    "    image_size=IMG_SIZE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(\"Classes of train:\", train_ds.class_names)\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "print(\"Classes of validation:\", val_ds.class_names)\n",
    "num_classes = len(val_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a256798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved class mapping to C:\\Users\\anar1\\Desktop\\CNN INGOLSTADT\\PHASE3MODEL\\class_mapping.json\n",
      "Mapping dictionary: {0: 'basement', 1: 'church', 2: 'entrance', 3: 'georgianum', 4: 'kreuztor', 5: 'ku', 6: 'pink', 7: 'room', 8: 'wfi'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Extract the class names (Keras automatically sorts them alphabetically)\n",
    "class_names = train_ds.class_names\n",
    "class_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "# 3. Save it as a JSON artifact in your models directory\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "mapping_path = os.path.join(MODEL_SAVE_DIR, 'class_mapping.json')\n",
    "\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(class_mapping, f, indent=4)\n",
    "\n",
    "print(f\"\\nSuccessfully saved class mapping to {mapping_path}\")\n",
    "print(\"Mapping dictionary:\", class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4866fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "# IF WE USE MOBILENET WE HAVE TO USE ITS OWN RESCALING WHICH I WILL PUT INTO THE LAYERS\n",
    "# layers.Rescaling(1./127.5, offset=-1)\n",
    "# train_ds1 = train_ds.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))\n",
    "# val_ds1   = val_ds.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a38ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DRY RUN LOGIC (smoke test before the attack)\n",
    "if TESTING_MODE:\n",
    "    print(\"testing mode activated and it helps smoke test\")\n",
    "    train_ds = train_ds.take(2)\n",
    "    val_ds = val_ds.take(1)\n",
    "\n",
    "#4) Speed, this is not that important but recommended\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210aae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b926f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 168, 3)\n",
      "Number of total training batches: 212\n",
      "Number of total training images (approximately): 6784\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)\n",
    "\n",
    "total_images = len(train_ds) * BATCH\n",
    "print(f\"Number of total training batches: {len(train_ds)}\")\n",
    "print(f\"Number of total training images (approximately): {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b20d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e353dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anar1\\AppData\\Local\\Temp\\ipykernel_11764\\2309580618.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  basemodel = tf.keras.applications.MobileNetV2(input_shape=(224,168,3),\n"
     ]
    }
   ],
   "source": [
    "basemodel = tf.keras.applications.MobileNetV2(input_shape=(224,168,3),\n",
    "                                              include_top=False,\n",
    "                                              weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "941ee319",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.trainable=False #i am seting the weights fixed or freezed so they do not get updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79295cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                                      layers.RandomRotation(0.1),\n",
    "                                      layers.RandomZoom(0.1),\n",
    "                                      layers.RandomTranslation(0.1,0.1),\n",
    "                                      layers.RandomContrast(0.1),\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cea6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.Sequential([layers.Input(shape=(224,168,3)),\n",
    "                         data_augmentation,\n",
    "                         layers.Rescaling(1./127.5,offset=-1),\n",
    "                         basemodel,\n",
    "                         layers.GlobalAveragePooling2D(), ## Prof. Voigtlaenders suggestion to use this instead of Flatten()\n",
    "                         \n",
    "                         layers.Dense(256,activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "                         layers.BatchNormalization(), # i learned this new, so we normalize the outputs of the layers so that mean =0 and var=1\n",
    "                         layers.Dropout(0.4), # also from the deep learning class\n",
    "                         \n",
    "                         layers.Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "                         layers.BatchNormalization(),\n",
    "                         layers.Dropout(0.3),\n",
    "                         \n",
    "                         layers.Dense(64,activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "                         layers.BatchNormalization(),\n",
    "                         layers.Dropout(0.2),\n",
    "                         \n",
    "                         layers.Dense(32,activation=\"relu\",kernel_initializer=\"he_normal\"),\n",
    "                         \n",
    "                         layers.Dense(NUM_CLASSES,activation=\"softmax\")]) #num_class in our class in PHASE 3 is equal to 9 since we have combined multiple subclasses to a unified class, before in phase 1 it was 21 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4fe608",
   "metadata": {},
   "outputs": [],
   "source": [
    "early=EarlyStopping(monitor=\"val_loss\",\n",
    "                    patience=5,\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6153e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase a\n",
    "basemodel.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae586be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 2s/step - accuracy: 0.4797 - loss: 1.6120 - val_accuracy: 0.8852 - val_loss: 0.3418\n",
      "Epoch 2/30\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 3s/step - accuracy: 0.9053 - loss: 0.3210 - val_accuracy: 0.9223 - val_loss: 0.2323\n",
      "Epoch 3/30\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 3s/step - accuracy: 0.9319 - loss: 0.2136 - val_accuracy: 0.9594 - val_loss: 0.1144\n",
      "Epoch 4/30\n",
      "\u001b[1m 10/212\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:23\u001b[0m 3s/step - accuracy: 0.9672 - loss: 0.1033"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[early]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
